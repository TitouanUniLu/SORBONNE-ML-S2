{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d6f4fb1-78d7-47f3-bc81-b3a6554f7882",
   "metadata": {},
   "source": [
    "# ML - TME 4 : Introduction à Pytorch (II)\n",
    "\n",
    "\n",
    "Nicolas Baskiotis (nicolas.baskiotis@sorbonne-universite.fr)  -- MLIA/ISIR, Sorbonne Université\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4587d8-8688-47bb-bb25-c187140515e3",
   "metadata": {},
   "source": [
    "## Préambule\n",
    "\n",
    "Dans cette deuxième partie, nous verrons les modules - brique de base de PyTorch - l'utilisation du GPU.\n",
    "\n",
    "Il se conclut sur une partie expérimentale sur MNIST.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7df826a-faae-4ee7-adf3-f7a2b049642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"La version de torch est : \",torch.__version__)\n",
    "print(\"Le calcul GPU est disponible ? \", torch.cuda.is_available())\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30410727-9c58-4a5a-9724-c6e980ae700a",
   "metadata": {},
   "source": [
    "## Module\n",
    "Dans le framework pytorch (et dans la plupart des frameworks analogues), <a href=\"https://pytorch.org/docs/stable/nn.html\">le module</a> est la brique de base qui permet de construire un réseau de neurones.Tous les modules se trouvent dans **torch.nn**. Un module permet de représenter en particulier :\n",
    "* une couche du réseau (linéaire : **nn.Linear**, convolution : **nn.convXd**, ...)\n",
    "* une fonction d'activation (tanh : **nn.Tanh**, sigmoïde : **nn.Sigmoid** , ReLu : **nn.ReLU**, ...)\n",
    "* une fonction de coût (MSE : **nn.MSELoss**, L1 :  **nn.L1Loss**, CrossEntropy binaire: **nn.BCE**, CrossEntropy : **nn.CrossEntropyLoss**, ...)\n",
    "* mais également des outils de régularisation (BatchNorm : **nn.BatchNorm1d**, Dropout : **nn.Dropout**, ...)\n",
    "* un ensemble de modules : en termes informatique, un module est un conteneur abstrait qui peut contenir d'autres conteneurs) : plusieurs modules peuvent être mis ensemble afin de former un nouveau module plus complexe. Ainsi, **nn.Sequential** permet d'enchaîner des modules, **nn.ModuleList** permet de faire une liste de module, ...\n",
    "\n",
    "Un objet module comporte une encapsulation qui permet de gérer automatiquement les paramètres à apprendre. Ainsi, lorsque plusieurs modules sont regroupés dans un même conteneur, tous les paramètres des sous-modules sont automatiquement considérés comme des paramètres du conteneur. Un module est muni :\n",
    "* d'une méthode **forward** qui permet de calculer la sortie du module à partir des entrées\n",
    "* d'une méthode **backward** qui permet d'effectuer la rétro-propagation (localement).\n",
    "* d'une méthode **parameters** qui permet d'obtenir tous les paramètres du module.\n",
    "\n",
    "Ci-dessous un exemple d'utilisation d'un module linéaire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abceb97c-ef11-49f0-b5fb-2b5a7a1654af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenseur de 5x10\n",
    "x = torch.randn(5,10)\n",
    "## Création d'une couche linéaire de dimension 10->1\n",
    "net = torch.nn.Linear(10, 1) \n",
    "## Passe forward du module \n",
    "print(\"Sortie du réseau\", net.forward(x))\n",
    "## Equivalent : \n",
    "print(\"Sortie du réseau\", net(x))\n",
    "\n",
    "## affiche la liste des paramètres du modèle\n",
    "print(\"Paramètres : \", list(net.parameters()))\n",
    "print(\"Paramètres et leurs noms : \", list(net.named_parameters()))\n",
    "\n",
    "## Création d'une fonction de loss aux moindres carrés\n",
    "mseloss = torch.nn.MSELoss()\n",
    "## on créé un optimiseur pour le réseau (paramètres w et b)\n",
    "optim = torch.optim.Adam(params=net.parameters(),lr=1e-3) \n",
    "## Juste pour info, ce n'est pas utile, les paramètres sont déjà initialisés.\n",
    "net.reset_parameters()\n",
    "## Calcul du coût\n",
    "l = mseloss(net(x),torch.randn(5,1))\n",
    "print(f\"Le coût est de {l.item()}\")\n",
    "\n",
    "# Passe backward \n",
    "optim.zero_grad()\n",
    "l.backward()\n",
    "optim.step() \n",
    "# Paramètres mis à jour \n",
    "print(\"Paramètres mis à jour : \",list(net.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2a1192-b351-43f2-80d4-7bb837bcd8bd",
   "metadata": {},
   "source": [
    "## Création d'un réseau de neurones\n",
    "\n",
    "Avec ces briques élémentaires, il est très facile de définir un réseau de neurones standard :\n",
    "* soit en utilisant le conteneur **nn.Sequential** qui permet d'enchaîner séquentiellement plusieurs modules, et qui chaîne automatiquement la sortie d'un module à l'entrée du suivant\n",
    "* soit en définissant à la main un nouveau module en le faisant hérité de la classe **nn.Module**. Dans ce cas, il est nécessaire de coder la méthode **forward** afin d'indiquer le comportement du module.\n",
    "\n",
    "Ci-dessous un exemple  pour créer un réseau à deux couches linéaires avec une fonction d'activation tanh des deux manières différentes. Vous remarquez qu'il n'y a pas besoin de définir la méthode **backward**, celle-ci est héritée du conteneur abstrait et ne fait qu'appeler séquentiellement en ordre inverse les méthodes **backward** des différents modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2526357-8a7e-4998-a3bd-f83541c835a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-2\n",
    "EPOCHS=50\n",
    "\n",
    "#Création d'un réseau à 1 couche cachée avec le module séquentiel\n",
    "netSeq = torch.nn.Sequential(torch.nn.Linear(10,5),torch.nn.Tanh(),torch.nn.Linear(5,1))\n",
    "    \n",
    "#Même réseau mais à la main\n",
    "class DeuxCouches(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.un = torch.nn.Linear(10,5)\n",
    "    self.act = torch.nn.Tanh()\n",
    "    self.deux = torch.nn.Linear(5,1)\n",
    "  def forward(self,x):\n",
    "    return self.deux(self.act(self.un(x)))\n",
    "\n",
    "netDeuxCouches = DeuxCouches()\n",
    "\n",
    "print(netSeq)\n",
    "print(netDeuxCouches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc50bd5-b57c-4e68-9f0d-ad66ffb65142",
   "metadata": {},
   "source": [
    "\n",
    "## GPU \n",
    "Afin d'utiliser un GPU lors des calculs, il est nécessaire de transférer les données et le modèle sur le GPU par l'intermédiaire de la fonction **to(device)** des tenseurs et des modules.  Il est impossible de faire une opération lorsqu'une partie des tenseurs sont sur GPU et l'autre sur CPU. Il faut que tous les tenseurs et paramètres soient sur le même device ! On doit donc s'assurer que le modèle, les exemples et les labels sont sur GPU pour faire les opérations.\n",
    "\n",
    "Par ailleurs, on peut connaître le device sur lequel est chargé un tenseur par l'intermédiaire de ```.device``` (mais pas pour un modèle, il faut aller voir les paramètres dans ce cas).\n",
    "\n",
    "Une manière simple d'utiliser un GPU quand il existe et donc d'avoir un code agnostique est la suivante : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f55e45-6710-41dd-b0bc-bffa504710d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Est-ce qu'un GPU est disponible ?\n",
    "use_cuda = torch.cuda.is_available()\n",
    "## Si oui, on le définit comme device\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "## On charge le modèle sur GPU\n",
    "## A faire avant la déclaration de l'optimiseur, sinon les paramètres optimisés ne seront pas les mêmes! \n",
    "netSeq = netSeq.to(device)\n",
    "# Equivalent à  (opération inplace)\n",
    "netSeq.to(device)\n",
    "\n",
    "optim = torch.optim.Adam(params=netSeq.parameters(),lr=EPS)\n",
    "\n",
    "## Si les paramètres ne sont pas sur le device, erreur !\n",
    "x = torch.randn(5,10)\n",
    "try:\n",
    "    print(netSeq(x))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "## On transfère les paramètres sur GPU (!! opération non inplace !!)\n",
    "x = x.to(device)\n",
    "print(\"Device du mini-batch : \", x.device)\n",
    "\n",
    "## Et cette fois-ci, ça marche\n",
    "print(netSeq(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f896dac2-127a-42e8-8f8a-a0ece2abc81b",
   "metadata": {},
   "source": [
    "## Boucle typique d'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf5d2c9-4021-4bcf-9592-e666a3e33999",
   "metadata": {},
   "source": [
    "Ci-dessous la boucle minimaliste typique en PyTorch pour l'apprentissage d'un modèle. N'hesitez pas à la modifier à votre convenance. Assurez vous de bien comprendre ce que fait chaque ligne de ce code.\n",
    "En particulier, on suppose que chaque modèle passé possède un attribut **name** pour pouvoir le logger dans tensorboard. Cet attribut n'existe pas par défaut, il faut l'ajouter manuellement (rappel : en python, il suffit de faire **net.name=\"mon réseau\"** pour créer un tel attribut...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29c3f92-b26c-44c8-adc1-9e56f95a11f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(yhat,y):\n",
    "    \"\"\" Calcul la précision \n",
    "        yhat: soit vecteur de taille N dans le cas binaire avec N proba de la classe 1, soit matrice NxK, K nombre de classes, score de chaque classe pour chaque exemple\n",
    "        y : vecteur des indexes ground truth\n",
    "    \"\"\"\n",
    "    if len(yhat.size())<2:\n",
    "        return ((yhat.view(-1)>0.5).int()==y).float().mean()\n",
    "    return (yhat.argmax(1)==y.view(-1)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411c43ec-f114-4efa-9a08-fa13ba599ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TB_PATH = \"/tmp/logtb\"\n",
    "\n",
    "def train(model, dataloaders, loss, eps,epochs,acc=True):\n",
    "    \"\"\"\n",
    "    Boucle d'apprentissage d'un modèle\n",
    "    \n",
    "        model: modèle à entrainer\n",
    "        dataloaders: dictionnaire avec : 'train' le dataloader de train, 'val' de validation et 'test' de test\n",
    "        loss: la fonction de coût à utiliser\n",
    "        epochs: le nombre d'époque\n",
    "        acc: calcul de l'accuracy ou non\n",
    "    \"\"\"\n",
    "    ## Création du log tensorboard\n",
    "    swriter = SummaryWriter(f\"{TB_PATH}/{model.name}\")\n",
    "    ## définition de l'optimiseur\n",
    "    optim = torch.optim.Adam(model.parameters(),eps=eps)\n",
    "    ## transfert du modèle sur gpu/cpu\n",
    "    model = model.to(device)\n",
    "    ## Boucle sur les époques\n",
    "    for e in range(epochs):\n",
    "        ## Boucle sur les différentes phases\n",
    "        for phase in ['train','val','test']:\n",
    "            if phase not in dataloaders:\n",
    "                continue\n",
    "            dl = dataloaders[phase]\n",
    "            ## Loss cumulative sur les batchs\n",
    "            cuml = 0.\n",
    "            ## Accuracy cumulative sur les batchs\n",
    "            cumacc = 0.\n",
    "            ## équivalent à with torch.no_grad() if phase != 'train'\n",
    "            with torch.set_grad_enabled(phase=='train'):\n",
    "                ## parcours du dataloader\n",
    "                for bx, by in dl:\n",
    "                    ## transfert sur gpu/cpu\n",
    "                    bx,by = bx.to(device), by.to(device)\n",
    "                    ## calcul des prédictions\n",
    "                    yhat = model(bx)\n",
    "                    ## calcul du coût\n",
    "                    l = loss(yhat,by)\n",
    "                    ## calcul de la précision et de l'erreur cumulées\n",
    "                    if acc :\n",
    "                        cumacc += accuracy(yhat.detach(),by)*len(bx)\n",
    "                    cuml += l.item()*len(bx)\n",
    "                    ## Mise à jour des poids\n",
    "                    if phase=='train':\n",
    "                        optim.zero_grad()\n",
    "                        l.backward()\n",
    "                        optim.step()\n",
    "            cuml = cuml/len(dl.dataset)\n",
    "            swriter.add_scalar(f\"loss/{phase}\",cuml,e)\n",
    "            if acc:\n",
    "                cumacc = cumacc/len(dl.dataset)\n",
    "                swriter.add_scalar(f\"prec/{phase}\",cumacc,e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cab56d-1a36-472e-9470-cf0bbf450ae9",
   "metadata": {},
   "source": [
    "# <font color=\"green\">  Expérimentations </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9562d43f-103e-4538-a10e-bf2ae242921d",
   "metadata": {},
   "source": [
    "##  Chargement du dataset MNIST\n",
    "Le code suivant permet de charger MNIST. Changez le chemin du téléchargement pour le mettre dans un endroit où il n'y a pas de problème de quota (par exemple **/temporary** sur la ppti dans les salles avec GPUs ou **/vrac** sur les autres). \n",
    "Chaque image est transformé ensuite pour centré/normé les données et applatit en un vecteur de taille **height*width**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11b4874-20ec-493b-ab51-3fc71a62a45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tensorboard import notebook\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "\n",
    "## Pensez à changer le /tmp/mnist à un chemin valable\n",
    "## une fois le dataset telecharge, mettre download=False !\n",
    "## Pour le test, train = False\n",
    "data_train_raw = datasets.MNIST( '/tmp/mnist',train=True, download=True)\n",
    "data_test_raw =  datasets.MNIST( '/tmp/mnist',train=False, download=True)\n",
    "\n",
    "data_shape = data_train_raw.data.shape \n",
    "height,width = data_shape[1],data_shape[2] # taille de l'image\n",
    "\n",
    "# On transforme les images en vecteurs de réels\n",
    "data_train = data_train_raw.data.float().reshape(-1,height*width)\n",
    "y_train = data_train_raw.targets\n",
    "data_test = data_test_raw.data.float().reshape(-1,height*width)\n",
    "y_test = data_test_raw.targets\n",
    "\n",
    "#Il est toujours mieux de normaliser les données (et que par rapport au train !!)\n",
    "meanData,stdData = data_train.mean(),data_train.std()\n",
    "data_train = (data_train-meanData)/stdData\n",
    "data_test = (data_test-meanData)/stdData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382fe5c3-a65a-4864-8136-a374e329452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On utilise un DataLoader pour faciliter les manipulations, on fixe arbitrairement la taille du mini batch à 32\n",
    "train_loader = DataLoader(TensorDataset(data_train,y_train),batch_size=32,shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(data_test,y_test),batch_size=32,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d4af69-2942-4491-bca8-fa05d840b863",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Affichage de quelques chiffres\n",
    "ex,lab = next(iter(test_loader))\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(ex[i].view(width,height), cmap='gray', interpolation='none')\n",
    "  plt.title(\"Label : {}\".format(lab[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969acb4a-c876-4f46-8676-c5c6bded690a",
   "metadata": {},
   "source": [
    "##  <font color=\"green\"> Premier réseau </font>\n",
    "\n",
    "Construire un réseau à deux couches avec par exemple 100 neurones dans la couche cachée et une activation tanh. Entraînez le sur une cinquantaine d'époques et visualisez les courbes de coût et de précision. Pour cela, utilisez dans un premier temps une <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\">**CrossEntropyLoss**</a>.  Lisez bien la documentation : ce coût prend en entrée les prédictions pour chaque classe pour chaque exemple et un vecteur d'entier indiquant les indexes des labels des classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a6f99c-a9e1-4b44-b555-ce6c516df91b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81aec88-9933-4a4d-82d1-6eefa8e86c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce52f9e9-0e16-4cd9-94ee-ec6a7f220107",
   "metadata": {},
   "source": [
    "Utilisez cette fois une <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss\"> **MSELoss**</a>. Attention, ce coût prend en entrée la prédiction pour chaque clase pour chaque exemple et une cible de même taille ! Vous aurez donc besoin de définir un coût auxiliaire qui prend les mêmes paramètres  que la **CrossEntropyLoss**, qui transforme chaque indexe en vecteur *one hot* et qui applique dessus le coût MSE afin de garder la même boucle d'apprentissage (regardez pour cela <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.functional.one_hot.html\">https://pytorch.org/docs/stable/generated/torch.nn.functional.one_hot.html</a>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3deb1c4-97dd-469d-a405-4df865bd1fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7055d791-b96a-4b9d-890d-b268d31337fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46f88e1d-b096-4f38-a788-e80b05879604",
   "metadata": {},
   "source": [
    "## Auto-encoder naïf\n",
    "\n",
    "Faîtes une classe **AutoEncoder** qui implémente un auto-encodeur : \n",
    "* un sous-module **encoder** qui applique une successsion de linéaires et de fonction d'activation, de dimension de plus en plus petite (exemple : DIM_Inx500, 500x100, 100x10)\n",
    "* un sous-module **decoder** qui applique une succession inverse de linéaires (exemple : 10x100, 100x500, 500xDIM_IN)\n",
    "* une méthode **forward** qui enchaîne une passe d'encodeur et une passe de décodeur.\n",
    "\n",
    "Cette classe permet d'*autoencoder* des exemples, c'est-à-dire trouver une représentation plus compacte et sémantiquement informative des exemples. Le réseau est appris sur un coût mesurant la différence entre la sortie du réseau et l'entrée d'origine.\n",
    "\n",
    "Proposez un dataloader pour apprendre un auto-encodeur. Scalez les sorties entre 0 et 1. Comparez les résultats sur MNIST en étudiant la *Tanh* et la *ReLU*, ainsi qu'un *BCELoss* comparé à un *MSELoss*. Tracez les images décodés durant l'apprentissage (avec **add_images** par exemple de *tensorboard*. \n",
    "\n",
    "Vous pouvez également comparer les *embeddings* appris (la couche de sortie de l'encodeur) avec **add_embeddings** de *tensorboard*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d625f19-a3a7-483b-a425-efa05d58a6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
